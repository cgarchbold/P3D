{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preforming a membership inference attack on protest classifiers.\n",
    "\n",
    "# First I need to import the CSV file for both UCLA Protest and VGKG predictions\n",
    "# Repeat for classifier trained on generated imagery\n",
    "\n",
    "ucla_df = pd.read_csv('./membership_csvs/result_ucla_stylvgkg.csv')\n",
    "vgkg_df = pd.read_csv('./membership_csvs/result_vgkg_stylvgkg.csv')\n",
    "\n",
    "ucla_df['label'] = 1  # UCLA label is 1\n",
    "vgkg_df['label'] = 0  # VGKG label is 0\n",
    "\n",
    "# Then I need to combine them and remove the imgpth label\n",
    "# We want to add a label for binary classification (0 for VGKG and 1 for UCLA)\n",
    "# Combine the DataFrames into a single DataFrame\n",
    "combined_df = pd.concat([ucla_df, vgkg_df], ignore_index=True)\n",
    "\n",
    "# Remove the 'imgpth' label column\n",
    "combined_df.drop(columns=['imgpath'], inplace=True)\n",
    "\n",
    "#print(combined_df)\n",
    "# Then train sklearn classifiers such as random forest and MLP models\n",
    "\n",
    "# Then I need to evaluate using accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/amo-d0/grad/cgar/miniconda3/envs/dp/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/u/amo-d0/grad/cgar/miniconda3/envs/dp/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but KMeans was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, homogeneity_score, completeness_score, rand_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df.drop('label', axis=1), combined_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, criterion='log_loss')\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Train a MLP Classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "mlp_predictions = mlp_classifier.predict(X_test)\n",
    "\n",
    "#Unsupervised\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)  # Assuming you want 2 clusters (VGKG and UCLA)\n",
    "kmeans.fit(X_scaled)\n",
    "kmeans_predicitons = kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.6145, Precision: 0.6320, Recall: 0.5702\n",
      "\n",
      "MLP Classifier:\n",
      "Accuracy: 0.6280, Precision: 0.6492, Recall: 0.5761\n",
      "\n",
      "Kmeans Classifier:\n",
      "Accuracy: 0.4940, Rand Index: 0.4998, Homogeneity: 0.0000, completeness: 1.0000\n",
      "0.6745126298186939\n",
      "0.6852636779696276\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_predictions)\n",
    "kmeans_accuracy = accuracy_score(y_test, kmeans_predicitons)\n",
    "\n",
    "rf_precision = precision_score(y_test, rf_predictions)\n",
    "mlp_precision = precision_score(y_test, mlp_predictions)\n",
    "\n",
    "rf_recall = recall_score(y_test, rf_predictions)\n",
    "mlp_recall = recall_score(y_test, mlp_predictions)\n",
    "\n",
    "kmeans_randindex = rand_score(y_test, kmeans_predicitons)\n",
    "kmeans_homogeneity = homogeneity_score(y_test, kmeans_predicitons)\n",
    "kmeans_completeness = completeness_score(y_test, kmeans_predicitons)\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}, Precision: {rf_precision:.4f}, Recall: {rf_recall:.4f}\")\n",
    "\n",
    "print(\"\\nMLP Classifier:\")\n",
    "print(f\"Accuracy: {mlp_accuracy:.4f}, Precision: {mlp_precision:.4f}, Recall: {mlp_recall:.4f}\")\n",
    "\n",
    "print(\"\\nKmeans Classifier:\")\n",
    "print(f\"Accuracy: {kmeans_accuracy:.4f}, Rand Index: {kmeans_randindex:.4f}, Homogeneity: {kmeans_homogeneity:.4f}, completeness: {kmeans_completeness:.4f}\")\n",
    "\n",
    "# Calculate AUC-ROC for Random Forest Classifier\n",
    "rf_probs = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "rf_auc_roc = roc_auc_score(y_test, rf_probs)\n",
    "print(rf_auc_roc)\n",
    "\n",
    "# Calculate AUC-ROC for MLP Classifier\n",
    "mlp_probs = mlp_classifier.predict_proba(X_test)[:, 1]\n",
    "mlp_auc_roc = roc_auc_score(y_test, mlp_probs)\n",
    "print(mlp_auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 1]\n",
      "[0 1 1 ... 0 1 0]\n",
      "0.567\n",
      "0.5603305785123966\n",
      "0.6699604743083004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = X_test.to_numpy()\n",
    "maxes = np.amax(a, axis=1)\n",
    "pred = np.where(maxes >= 0.95, 1, 0)\n",
    "print(pred)\n",
    "print(y_test.to_numpy())\n",
    "\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(precision_score(y_test, pred))\n",
    "print(recall_score(y_test, pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
